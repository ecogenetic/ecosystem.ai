---
title: API's
description: Configure API's to test your scoring.
---

# Intro

An Application Programming Interface (API) is a set of defined rules that enables different software systems to communicate with each other. It allows developers to access data, functionality, or services provided by one system from another system, either within the same organization or across different organizations.

## Key Features

This is a convenient way to test your scoring API's as configured by the deployment steps. Once configuration has been pushed to the runtime engine, you can score against it and obtain results.

Assign a descriptive name and the url path to the runtime scoring engine. This url can be publicly accessible or in a private cluster. Note that each platform and deployment cluster configuration will have it's own standards and naming conventions. Typically there are two endpoints to use for testing namely ```/invocations``` and ```/response```. The payloads for these differ depending on the case.

![image](/images/configuration/api/api-01.png)

The ```/invocations``` API has a number of standard parameters, but there is also a ```Params``` parameter that can contain a JSON configuration depending on the use-case and if you modified any pre- or post-scoring plugins that use this Params for additional values.

![image](/images/configuration/api/api-02.png)

Here are the options for Params:
***Model Based Scoring***
If there are no additional parameters to process then use:
```json
{}
```

If you don't have a data lookup set, and want to pass model scoring parameters via the api, then use this format:
```json
{
    "input":["scoring_variable1","scoring_variable2"],
    "value":["0.3333","open"]
}
```

***Dynamic Model***
Use this parameter style for dynamic models. The key thing to note is that variables can be left blank if no context needs to be set.
```json
{
    "input":["contextual_variable_one","contextual_variable_two"],
    "value":["",""]
}
```

***Deep Learning: Tensorflow and PyTorch Models***
For Tensorflow or PyTorch models:
```json
{
    "input":["text"],
    "value":["Place text here"],
    "type":"dense_1"
}
```
Question/Answer approaches:
```json
{
    "input":["text","question"],
    "value":["BBC Japan was a general entertainment Channel. Which operated between December 2004 and April 2006.","When did BBC Japan start broadcasting?"],
    "type":"qa"
}
```

![image](/images/configuration/api/api-03.png)

The API payload is populated by your stack when calling the scoring engine. Here's a payload example:
```
http://ecosystem-runtime:8091/invocations
```
Payload to call API, note that the params can be URL Encoded or in plain text.:
```json
{
    "campaign":"spend_personality_master",
    "subcampaign":"spend_personality_master",
    "channel":"app",
    "customer":"590",
    "userid":"ecosystem",
    "numberoffers":"1",
    "params":"%22%7B%7D%22"
}
```

The ```/response``` API is used to respond with selected item from ```/invocations``` response. For example a list of products can be returned for use in an app, web or other application. Once the user accept a option then this API is called.

![image](/images/configuration/api/api-04.png)

Here is an example of a shorter version of payload, or use the entire response JSON payload.
```json
{
    "uuid":"",
    "offers_accepted":[{"offer_name":""}],
    "channel_name":"",
    "transaction_id":""
}
```
Note that different models will process responses differently. Dynamic models can be set to converge in real-time.
